---
title: "YRBS Logistical Trend Analysis"
format: html
editor: visual
---

## Statewide Traditional

### Packages & Working Directory

```{r message = FALSE, warning = FALSE, eval=FALSE}

# Load Packages
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman")

pacman::p_load(
  tidyr,      # for data tidying operations like 'spread' & 'gather'
  dplyr,      # data manipulation operations, filter/mutate/select/etc.
  readxl,     # read data from Excel files (.xlsx and .xls)
  openxlsx,   # reading, writing, & editing Excel files without Java
  srvyr,      # a helper for using dplyr and survey weighted analysis
  survey,     # analysis of complex survey samples
  stringr,    # consistent, simple tools to work with strings of chr
  purrr       # Enhances programming for mapping/iterating over lists
)


#options(scipen=999) # avoid the use of scientific notation (e.g., 1e+03) 
options(survey.lonely.psu="adjust") # Adjust for Lonely PSU
options(survey.adjust.domain.lonely=TRUE) # Adjust for Lonely PSU

```

### Trend by Overall

```{r message = FALSE, warning = FALSE, eval=FALSE}

# Decided to perform trend Analysis from 2011 to 2023, and to include only 2011 to present on dashboards, highlights, etc. Can redo later for 2003 to 2023



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", 
                                             sheet = "Overall Trend") %>%
   filter(Trend_Category == "Overall") %>%
   mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Race_Group_3, Grade,Primary_Samp_Unit,Stratum,Final_Weight)





############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Sex = factor(Sex), Race_Group_3 = factor(Race_Group_3), Grade = factor(Grade))

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~ Sex + Race_Group_3 + Grade + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)





######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)





################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


trend_results <- trend_results %>%
  rename(Long_Term_Trend = Long_Term_Trend.x,
         Short_Term_Trend = Short_Term_Trend.x) %>%
  select(-c(Long_Term_Trend.y,
            Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()




  
trend_results_overall <- trend_results

    
# View the updated dataframe
head(trend_results_overall)
```

### Trend by Grade

#### 9th

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Grade Trend") %>%
  filter(Trend_Category == "9th") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Grade == "9th",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, 
         all_of(roi_years),
         Sex,
         Race_Group_3,
         #Grade,
         Primary_Samp_Unit,
         Stratum,Final_Weight)






############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Sex = factor(Sex),
           Race_Group_3 = factor(Race_Group_3), 
           #Grade = factor(Grade)
           )

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~ Sex + Race_Group_3 + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)





######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)




################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()




  
  
trend_results_grade_09 <- trend_results %>%

    
# View the updated dataframe
head(trend_results_grade_09)


```

#### 10th

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Grade Trend") %>%
  filter(Trend_Category == "10th") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))






# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Grade == "10th",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Race_Group_3,Primary_Samp_Unit,Stratum,Final_Weight)







############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Sex = factor(Sex),
           Race_Group_3 = factor(Race_Group_3), 
           #Grade = factor(Grade)
           )

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~ Sex + Race_Group_3 + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)




######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)





################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()






  
  
trend_results_grade_10 <- trend_results 

    
# View the updated dataframe
head(trend_results_grade_10)
```

#### 11th

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Grade Trend") %>%
  filter(Trend_Category == "11th") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Grade == "11th",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Race_Group_3,Primary_Samp_Unit,Stratum,Final_Weight)


############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Sex = factor(Sex),
           Race_Group_3 = factor(Race_Group_3), 
           #Grade = factor(Grade)
           )

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~ Sex + Race_Group_3 + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)





######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)


################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





  
  
trend_results_grade_11 <- trend_results



# View the updated dataframe
head(trend_results_grade_11)

```

#### 12th

```{r message = FALSE, warning = FALSE, eval=FALSE}




######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Grade Trend") %>%
  filter(Trend_Category == "12th") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Grade == "12th",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Race_Group_3,Primary_Samp_Unit,Stratum,Final_Weight)


############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Sex = factor(Sex),
           Race_Group_3 = factor(Race_Group_3), 
           #Grade = factor(Grade)
           )

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~ Sex + Race_Group_3 + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)






######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)




################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()






  
  
trend_results_grade_12 <- trend_results



# View the updated dataframe
head(trend_results_grade_12)




```

### Trend by Sex

#### Female

```{r message = FALSE, warning = FALSE, eval=FALSE}
######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Sex Trend") %>%
  filter(Trend_Category == "Female") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


         
# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Sex == "Female",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Race_Group_3, Grade,Primary_Samp_Unit,Stratum,Final_Weight)




############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(
           #Sex = factor(Sex),
           Race_Group_3 = factor(Race_Group_3), 
           Grade = factor(Grade))

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~Race_Group_3 + Grade + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)





######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()




  
  
trend_results_sex_female <- trend_results



# View the updated dataframe
head(trend_results_sex_female)
```

#### Male

```{r message = FALSE, warning = FALSE, eval=FALSE}

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Sex Trend") %>%
  filter(Trend_Category == "Male") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Sex == "Male",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Identify ROIs with data for 4 or more survey years of data (We decided as a YRBS team that only ROI's with 4 data points/4 years total of data between the trend years being used, would be acceptable to do trend analysis on. Such that an ROI that has 2011, 2013, and 2017 data/prevalence estimate, would not have trend anlaysis performed on it)
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, names_to = "ROI_Indicator_Code", values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), .groups = 'drop') %>%
  filter(unique_years >= 4) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Race_Group_3, Grade,Primary_Samp_Unit,Stratum,Final_Weight)


############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_wtd <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE,
                     )
  data_filtered <- data_wtd %>%
    mutate(Race_Group_3 = factor(Race_Group_3), Grade = factor(Grade))

  if (nrow(data_filtered) < 4 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }

  
  base_formula <- paste(column_name, "~Race_Group_3 + Grade + Survey_Year")# fix to test for yearly linear trend
  models <- list(
    "linear" = base_formula,
    "quadratic" = paste(base_formula, "+ I(Survey_Year^2)"),
    "cubic" = paste(base_formula, "+ I(Survey_Year^2) + I(Survey_Year^3)")
  )
#browser() #debugging tool
  results <- lapply(models, function(f) {
    model <- tryCatch({ #Used to see where the model is failing
      svyglm(as.formula(f), design = data_filtered, family = quasibinomial(link = "logit"))
    }, error = function(e) {
      message("Error fitting model: ", e$message)
      return(NULL)
    })

    if (is.null(model)) {
      return("Model fitting error")
    }

    coef_summary = summary(model)$coefficients
    if (length(coef_summary) == 0) {
      return("Model fitting error: No coefficients")
    }
    
#browser() # debug
    highest_order_term <- tail(rownames(coef_summary), 1)#  Changed to rownames() from names() - now runs
    
    if (!is.null(highest_order_term) && highest_order_term %in% rownames(coef_summary)) {
      p_value = coef_summary[highest_order_term, "Pr(>|t|)"]# statistic changed to |t| from |z|
      coefficient = coef(model)[highest_order_term]
      if (p_value <= 0.05) {
        if (coefficient > 0) {
          return("Significant Increase")
        } else {
          return("Significant Decrease")
        }
      } else {
        return("No Change")
      }
    } else {
      return("Coefficient not available or model did not converge")
    }
  })

  return(data.frame(ROI_Indicator_Code = column_name, 
                    CUBIC_Term_Trend = results$cubic,
                    QUAD_Term_Trend = results$quadratic,
                    LIN_Term_Trend=results$linear))
}




# Apply function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


long_trend_results <- long_trend_results %>%
  rename(Long_Term_Trend = LIN_Term_Trend) %>%
  select(ROI_Indicator_Code,
         Long_Term_Trend
         )

# Show results
head(long_trend_results)





######### Short Term Trend ###############



analyze_short_term_trend_ttest <- function(data, column_name) {
  # Define the short-term years
  short_term_years <- c(2019, 2023)

  # Filter for short-term years and ensure all necessary variables are selected
  data_filtered <- data %>%
    filter(Survey_Year %in% short_term_years) %>%
    select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
    mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis

  # Check if data is available for both years
  if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered[[column_name]])]))) {
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
  }

  # Continue with data that doesn't have NA responses
  data_filtered <- data_filtered %>% filter(!is.na(response))

  # Create survey design object including the response variable
  survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                             strata = ~Stratum,
                             weights = ~Final_Weight,
                             data = data_filtered,
                             nest = TRUE) 
  
  # Perform Welch's t-test using the survey design object
  ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)

  # head t-test results
  head(ttest_result)

  # Check significance and interpret the results
  if (ttest_result$p.value < 0.05) {
    trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
  } else {
    trend <- "No Change"
  }

  return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}

# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, short_trend_results, by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)


# trend_results <- trend_results %>%
#   rename(Long_Term_Trend = Long_Term_Trend.x,
#          Short_Term_Trend = Short_Term_Trend.x) %>%
#   select(-c(Long_Term_Trend.y,
#             Short_Term_Trend.y))



# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))


head(trend_results)

# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()






  
  
trend_results_sex_male <- trend_results



# View the updated dataframe
head(trend_results_sex_male)

```

### Trend By Race_Group_6

#### 6.1 - Alaska Native/American Indian

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############

# Import trend data from a specific Excel sheet. Replace any occurrences of "Suppressed" with NA.
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  filter(Trend_Category == "Alaska Native/American Indian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


 # Load raw statewide survey data, filtering correctly and specific years. Recode certain survey responses for analysis as it needs 0,1 not 1,2
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "Alaska Native/American Indian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))


# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)




trend_results_race_6_ANAI <- trend_results

head(trend_results_race_6_ANAI)
                                 
```

#### 6.2 - Black/African American

```{r message = FALSE, warning = FALSE, eval=FALSE}

### Please note for this demographic, the sample size was too small and is only adjusted for sex and NOT grade, as the rest are. 

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  filter(Trend_Category == "Black/African American") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))

# Load the raw data set to be used in trend analysis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "Black/African American",
         Survey_Year %in% c(2011, 2013, 2015, 2017, 2019, 2023)) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))

# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()


head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)





trend_results_race_6_BlkAA <- trend_results

head(trend_results_race_6_BlkAA)
                                    
                               
```

#### 6.3 - White

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  filter(Trend_Category == "White") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



 # Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "White",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))


# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)







trend_results_race_6_white <- trend_results

head(trend_results_race_6_white)
                                    
                                  
```

#### 6.4 - Hispanic/Latino

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  filter(Trend_Category == "Hispanic/Latino") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




 # Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "Hispanic/Latino",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)






trend_results_race_6_HispLat <- trend_results

head(trend_results_race_6_HispLat)
                                    
```

#### 6.5 - Other Races

```{r message = FALSE, warning = FALSE, eval=FALSE}

######## Import Raw and Analyzed Excel Files ###############

# *** If this code is not working, check analysis excel file to see if it says "Other Race" with no "s"

yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  mutate(ROI_Indicator_Code = as.character(ROI_Indicator_Code)) %>%
  filter(Trend_Category == "Other Races") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


 # Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "Other Races",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  mutate(ROI_Indicator_Code = as.character(ROI_Indicator_Code)) %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)







trend_results_race_6_other_race <- trend_results

head(trend_results_race_6_other_race)
                                    
```

#### 6.6 - Multiple Races

```{r message = FALSE, warning = FALSE, eval=FALSE}


# *** If this code is not working, check analysis excel file to see if it says "Multiple Race" with no "s"

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend") %>%
  filter(Trend_Category == "Multiple Races") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




 # Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_6 == "Multiple Races",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)





trend_results_race_6_mult_race <- trend_results

head(trend_results_race_6_mult_race)
                                    
                                    
```

### Trend By Race_Group_3

#### 3.1 - Alaska Native/American Indian

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_3 Trend") %>%
  filter(Trend_Category == "Alaska Native/American Indian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


         
         
 # Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_3 == "Alaska Native/American Indian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)






trend_results_race_3_ANAI <- trend_results

head(trend_results_race_3_ANAI)
                                 
```

#### 3.2 - White

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_3 Trend") %>%
  filter(Trend_Category == "White") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_3 == "White",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))


# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)







trend_results_race_3_white <- trend_results

head(trend_results_race_3_white)
                                    
                                  
```

#### 3.3 - Other/Multiple

```{r message = FALSE, warning = FALSE, eval=FALSE}

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_3 Trend") %>%
  filter(Trend_Category == "Other/Multiple") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))





# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_3 == "Other/Multiple",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)







trend_results_race_3_other_race_mult <- trend_results

head(trend_results_race_3_other_race_mult)
                                    

```

### Trend By Race_Group_4

#### 4.1 - Alaska Native/American Indian

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_4 Trend") %>%
  filter(Trend_Category == "Alaska Native/American Indian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_4 == "Alaska Native/American Indian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)






trend_results_race_4_ANAI <- trend_results

head(trend_results_race_4_ANAI)
                                 
```

#### 4.2 - Hispanic/Latino

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_4 Trend") %>%
  filter(Trend_Category == "Hispanic/Latino") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_4 == "Hispanic/Latino",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)







trend_results_race_4_HispLat <- trend_results

head(trend_results_race_4_HispLat)
                                    
```

#### 4.3 - White

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_4 Trend") %>%
  filter(Trend_Category == "White") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_4 == "White",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)






trend_results_race_4_white <- trend_results

head(trend_results_race_4_white)
                                    
                                  
```

#### \*4.4 - Other/Multiple

```{r message = FALSE, warning = FALSE, eval=FALSE}

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_4 Trend") %>%
  filter(Trend_Category == "Other/Multiple") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_4 == "Other/Multiple",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 



trend_results_race_4_other_race_mult <- trend_results

head(trend_results_race_4_other_race_mult)
                                    

```

### Trend By Race_Group_8

#### 8.1 - Alaska Native/American Indian

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Alaska Native/American Indian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Alaska Native/American Indian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)








trend_results_race_8_ANAI <- trend_results

head(trend_results_race_8_ANAI)
                                 
```

#### 8.2 - Asian

```{r message = FALSE, warning = FALSE, eval=FALSE}

### Please note for this demographic, the sample size was too small and is only adjusted for sex and NOT grade, as the rest are.

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Asian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Asian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)






trend_results_race_8_asian <- trend_results

head(trend_results_race_8_asian)
                                    
                                  
```

#### 8.3 - Black/African American

```{r message = FALSE, warning = FALSE, eval=FALSE}

### Please note for this demographic, the sample size was too small and is only adjusted for sex and NOT grade, as the rest are.

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Black/African American") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Black/African American",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)





######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 



trend_results_race_8_BlkAA <- trend_results

head(trend_results_race_8_BlkAA)
                                    
                               
```

#### 8.4 - Hispanic/Latino

```{r message = FALSE, warning = FALSE, eval=FALSE}

### Please note for this demographic, the sample size was too small to adjusted for sex and grade, as the rest are.


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Hispanic/Latino") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Hispanic/Latino",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 


trend_results_race_8_HispLat <- trend_results

head(trend_results_race_8_HispLat)
                                    
```

#### 8.5 - Hisp/Lat Mult Race

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Hisp/Lat Mult Race") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Hisp/Lat Mult Race",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


##Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 



trend_results_race_8_HispLat_Mult <- trend_results

head(trend_results_race_8_HispLat_Mult)
```

#### 8.6 - Native Haw/Other PI

```{r message = FALSE, warning = FALSE, eval=FALSE}

### Please note for this demographic, the sample size was too small and is only adjusted for sex and NOT grade, as the rest are.

######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Native Haw/Other PI") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Native Haw/Other PI",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 


trend_results_race_8_NWPI <- trend_results

head(trend_results_race_8_NWPI)
```

#### 8.7 - Non Hisp/Lat Mult Race

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "Non Hisp/Lat Mult Race") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "Non Hisp/Lat Mult Race",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)





######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 


trend_results_race_8_Non_HispLat_Mult <- trend_results

head(trend_results_race_8_Non_HispLat_Mult)
                                    
```

#### 8.8 - White

```{r message = FALSE, warning = FALSE, eval=FALSE}



######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend") %>%
  filter(Trend_Category == "White") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_Group_8 == "White",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)



trend_results_race_8_white <- trend_results

head(trend_results_race_8_white)
                                    
                                  
```

### Trend By Race_ANAI

#### ANAI.1 - Alaska Native/American Indian

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_ANAI Trend") %>%
  filter(Trend_Category == "Alaska Native/American Indian") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



         
# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_ANAI == "Alaska Native/American Indian",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)






######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 



trend_results_race_ANAI <- trend_results

head(trend_results_race_ANAI)
                                 
```

#### ANAI.2 - Non AN/AI

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_ANAI Trend") %>%
  filter(Trend_Category == "Non AN/AI") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))


# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_ANAI == "Non AN/AI",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))




# Remove whitespcae
remove_whitespace_from_all_columns <- function(df) {
  df[] <- lapply(df, function(x) {
    if (is.character(x)) {
      return(trimws(x, which = "both"))
    } else {
      return(x)
    }
  })
  return(df)
}

# Apply the function to your dataframe
raw_stwd_general <- remove_whitespace_from_all_columns(raw_stwd_general)
yrbs_master_analysis_stwd_trend <- remove_whitespace_from_all_columns(yrbs_master_analysis_stwd_trend)



#head(yrbs_master_analysis_stwd_trend)
#head(raw_stwd_general)

# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)





######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
   # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
          Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`),
                                    "Too few data points for analysis",
                                    Short_Term_Trend)
         ) %>%
  ungroup()





#head(trend_results)





trend_results_race_non_ANAI <- trend_results

head(trend_results_race_non_ANAI)
```

### Trend By Race_HispLat

#### Hisp.1 - Hispanic/Latino

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_HispLat Trend") %>%
  filter(Trend_Category == "Hispanic/Latino") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))




# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_HispLat == "Hispanic/Latino",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 



trend_results_race_HispLat <- trend_results

head(trend_results_race_HispLat)
                                    
```

#### Hisp.2 - Non Hisp/Lat

```{r message = FALSE, warning = FALSE, eval=FALSE}


######## Import Raw and Analyzed Excel Files ###############


yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_HispLat Trend") %>%
  filter(Trend_Category == "Non Hisp/Lat") %>%
  mutate(across(everything(), ~ ifelse(. == "Suppressed", NA, .)))



# Load the raw data set to be used in trend analyis
raw_stwd_general <- read.xlsx("raw_yrbs_allyears_statewide_trad_cleaned.xlsx") %>%
  filter(Race_HispLat == "Non Hisp/Lat",
         Survey_Year %in% c(2011,
                            2013, 
                            2015, 
                            2017,
                            2019, 
                            2023
                            )) %>%
  mutate(across(matches("^(QN|V).*[RP]"), ~ ifelse(. == 2, 0, ifelse(. == 1, 1, NA))))



# Determine which survey questions (ROI - Response of Interest) have data across at least two distinct survey years
roi_years <- raw_stwd_general %>%
  select(matches("^(QN|V).*[RP]"), Survey_Year) %>%
  pivot_longer(cols = -Survey_Year, 
               names_to = "ROI_Indicator_Code", 
               values_to = "value") %>%
  group_by(ROI_Indicator_Code) %>%
  summarise(unique_years = n_distinct(Survey_Year), 
            .groups = 'drop') %>%
  filter(unique_years >= 2) %>%
  pull(ROI_Indicator_Code)

# Filter the main data set to include only those ROIs, also ensuring to keep necessary demographic variables
filtered_raw_stwd_general <- raw_stwd_general %>%
  select(Survey_Year, all_of(roi_years), Sex, Grade, Primary_Samp_Unit,Stratum,Final_Weight)



############ Long Term Trend ###############


#Trend Analysis Function
analyze_trend_logistic <- function(data, column_name) {
  data_filtered <- data %>% 
    # Survey Design for YRBS Statewide
    as_survey_design(ids = Primary_Samp_Unit,
                     strata = Stratum,
                     weights = Final_Weight,
                     nest = TRUE)
  
  data_filtered <- data_filtered %>%
    mutate(Sex = factor(Sex), Grade = factor(Grade))
  
  if (nrow(data_filtered) < 2 || length(unique(data_filtered$variables$Survey_Year)) < 4) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Too few data points for analysis"))
  }
  
  base_formula <- paste(column_name, "~ Sex + Grade + Survey_Year") 
  # Fit the model using logistic regression
  model <- tryCatch({
    svyglm(as.formula(base_formula), design = data_filtered, family = quasibinomial(link = "logit"))
  }, error = function(e) {
    message("Error fitting model: ", e$message)
    return(NULL)
  })
  
  # Check if model fitting was successful
  if (is.null(model)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error"))
  }
  
  # Check for coefficients
  if (!("Survey_Year" %in% names(coef(model)))) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No valid coefficient for Survey_Year"))
  }
  
  coef_summary = summary(model)$coefficients
  if (length(coef_summary) == 0) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Model fitting error: No coefficients"))
  }
  
  # Determine the significance and direction of the trend
  p_value = coef_summary["Survey_Year", "Pr(>|t|)"]
  coefficient = coef(model)["Survey_Year"]
  
  if (is.na(p_value)) {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "P-value is NA"))
  }
  
  if (p_value <= 0.05) {
    if (coefficient > 0) {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Increase"))
    } else {
      return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "Significant Decrease"))
    }
  } else {
    return(data.frame(ROI_Indicator_Code = column_name, Long_Term_Trend = "No Change"))
  }
}

# Apply the function to each ROI_Indicator_Code that has sufficient data
long_trend_results <- lapply(names(filtered_raw_stwd_general)[-1], function(column_name) {
  analyze_trend_logistic(filtered_raw_stwd_general, column_name)
}) %>% bind_rows()

# Show results
head(long_trend_results)







######### Short Term Trend ###############

analyze_short_term_trend_ttest <- function(data, column_name) {
    # Define the short-term years
    short_term_years <- c(2019, 2023)
    
    # Filter for short-term years and ensure all necessary variables are selected
    data_filtered <- data %>%
        filter(Survey_Year %in% short_term_years) %>%
        select(Primary_Samp_Unit, Stratum, Final_Weight, Survey_Year, all_of(column_name)) %>%
        mutate(response = get(column_name) == 1)  # Create a binary response variable for the analysis
    
    # Check if data is available for both years
    if (!all(short_term_years %in% unique(data_filtered$Survey_Year[!is.na(data_filtered$response)]))) {
        return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = "Too few data points for analysis"))
    }
    
    # Continue with data that doesn't have NA responses
    data_filtered <- data_filtered %>% filter(!is.na(response))
    
    # Create survey design object including the response variable
    survey_design <- svydesign(ids = ~Primary_Samp_Unit,
                               strata = ~Stratum,
                               weights = ~Final_Weight,
                               data = data_filtered,
                               nest = TRUE) 
    
    # Perform Welch's t-test using the survey design object
    ttest_result <- svyttest(response ~ as.factor(Survey_Year), survey_design)
    
    # head t-test results
    head(ttest_result)
    
    # Check significance and interpret the results
    if (!is.na(ttest_result$p.value) && ttest_result$p.value < 0.05) {
        trend <- ifelse(ttest_result$estimate > 0, "Significant Increase", "Significant Decrease")
    } else {
        trend <- "No Change"
    }
    
    return(data.frame(ROI_Indicator_Code = column_name, Short_Term_Trend = trend))
}



# Apply the short-term function to each ROI_Indicator_Code
short_trend_results <- lapply(names(raw_stwd_general)[grep("^(QN|V).*[RP]", names(raw_stwd_general))], function(column_name) {
  analyze_short_term_trend_ttest(raw_stwd_general, column_name)
}) %>% bind_rows()

head(short_trend_results)



################### Join Together with Trend Tables ############

# Combine long-term and short-term results
combined_trend_results <- left_join(long_trend_results, 
                                    short_trend_results, 
                                    by = "ROI_Indicator_Code")

#head(combined_trend_results)





# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
trend_results <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, 
          ROI_Indicator_Code, 
          Trend_Category)


# Function to check for three consecutive NAs in a set of columns
check_consecutive_nas <- function(year_values) {
  na_run_lengths <- rle(is.na(year_values))$lengths[rle(is.na(year_values))$values]
  any(na_run_lengths >= 3)
}

# Convert all columns representing years to numeric
trend_results <- trend_results %>%
  mutate(across(matches("^\\d+$"), as.numeric))




# Merge and mutate Long_Term_Trend
trend_results <- trend_results %>%
  rowwise() %>%
  mutate(Long_Term_Trend = ifelse(check_consecutive_nas(c_across(`2011`:`2023`)), 
                                  "Too few data points for analysis", 
                                  Long_Term_Trend),
         Short_Term_Trend = ifelse(is.na(`2019`) | is.na(`2023`), 
                                   "Too few data points for analysis", 
                                   Short_Term_Trend)) %>%
  ungroup()





head(trend_results)


 


trend_results_race_non_HispLat <- trend_results

head(trend_results_race_non_HispLat)
```

## Combine & Export

#### Combine Overall

```{r message = FALSE, warning = FALSE, eval=FALSE}

################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Overall Trend")

#head(yrbs_master_analysis_stwd_trend)




# Merge Long_Term_Trend into yrbs_master_stwd_trend based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(trend_results_overall %>% select(ROI_Indicator_Code, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Overall Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)





```

#### Combine Grade

```{r message = FALSE, warning = FALSE, eval=FALSE}

######################## Combine all together #######################


# Combine the data frames
combined_trend_results <- bind_rows(trend_results_grade_12, 
                                    trend_results_grade_11, 
                                    trend_results_grade_10, 
                                    trend_results_grade_09)

# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("9th", "10th", "11th", "12th"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)






# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Grade Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("9th", "10th", "11th", "12th"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("9th",
                                          "10th",
                                          "11th",
                                          "12th")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Grade Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)




```

#### Combine Sex

```{r message = FALSE, warning = FALSE, eval=FALSE}

######################## Combine all together #######################



# Combine the data frames
combined_trend_results <- bind_rows(trend_results_sex_female, 
                                    trend_results_sex_male)
# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)






# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Sex Trend")

head(yrbs_master_analysis_stwd_trend)




# Merge Long_Term_Trend into yrbs_master_stwd_trend based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Sex Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)





```

#### Combine Race_Group_6

```{r message = FALSE, warning = FALSE, eval=FALSE}


######################## Combine all together #######################




# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_6_ANAI, 
                                    trend_results_race_6_BlkAA,
                                    trend_results_race_6_white,
                                    trend_results_race_6_HispLat,
                                    trend_results_race_6_other_race,
                                    trend_results_race_6_mult_race)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Black/African American",
                                                           "Hispanic/Latino",
                                                           "Multiple Races",
                                                           "Other Races",
                                                           "White"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)





################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_6 Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Black/African American",
                                                           "Hispanic/Latino",
                                                           "Multiple Races",
                                                           "Other Races",
                                                           "White"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Alaska Native/American Indian",
                                                           "Black/African American",
                                                           "Hispanic/Latino",
                                                           "Multiple Races",
                                                           "Other Races",
                                                           "White")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_Group_6 Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)





```

#### Combine Race_Group_3

```{r message = FALSE, warning = FALSE, eval=FALSE}

######################## Combine all together #######################


# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_3_ANAI, 
                                    trend_results_race_3_white,
                                    trend_results_race_3_other_race_mult)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Other/Multiple",
                                                           "White"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)



################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_3 Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Other/Multiple",
                                                           "White"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Alaska Native/American Indian",
                                                           "Other/Multiple",
                                                           "White")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_Group_3 Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)






```

#### Combine Race_Group_4

```{r message = FALSE, warning = FALSE, eval=FALSE}


######################## Combine all together #######################




# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_4_ANAI, 
                                    trend_results_race_4_HispLat,
                                    trend_results_race_4_white,
                                    trend_results_race_4_other_race_mult,
                                    )


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Hispanic/Latino",
                                                           "White",
                                                           "Other/Multiple"
                                                           ))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)





################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_4 Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Hispanic/Latino",
                                                           "White",
                                                           "Other/Multiple"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Alaska Native/American Indian",
                                                           "Hispanic/Latino",
                                                           "White",
                                                           "Other/Multiple")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_Group_4 Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)






```

#### Combine Race_Group_8

```{r message = FALSE, warning = FALSE, eval=FALSE}


######################## Combine all together #######################




# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_8_ANAI, 
                                    trend_results_race_8_asian,
                                    trend_results_race_8_BlkAA,
                                    trend_results_race_8_HispLat,
                                    trend_results_race_8_HispLat_Mult,
                                    trend_results_race_8_NWPI,
                                    trend_results_race_8_Non_HispLat_Mult,
                                    trend_results_race_8_white,
                                    )


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                   "Asian",
                                                   "Black/African American",
                                                   "Hispanic/Latino",
                                                   "Hisp/Lat Mult Race",
                                                   "Native Haw/Other PI",
                                                   "Non Hisp/Lat Mult Race",
                                                   "White"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)





################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_Group_8 Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                   "Asian",
                                                   "Black/African American",
                                                   "Hispanic/Latino",
                                                   "Hisp/Lat Mult Race",
                                                   "Native Haw/Other PI",
                                                   "Non Hisp/Lat Mult Race",
                                                   "White"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Alaska Native/American Indian",
                                                   "Asian",
                                                   "Black/African American",
                                                   "Hispanic/Latino",
                                                   "Hisp/Lat Mult Race",
                                                   "Native Haw/Other PI",
                                                   "Non Hisp/Lat Mult Race",
                                                   "White")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_Group_8 Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)





```

#### Combine Race_ANAI

```{r message = FALSE, warning = FALSE, eval=FALSE}

######################## Combine all together #######################




# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_ANAI, 
                                    trend_results_race_non_ANAI)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Non AN/AI"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)





################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_ANAI Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Alaska Native/American Indian",
                                                           "Non AN/AI"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Alaska Native/American Indian",
                                                           "Non AN/AI")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_ANAI Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)






```

#### Combine Race_HispLat

```{r message = FALSE, warning = FALSE, eval=FALSE}

######################## Combine all together #######################




# Combine the data frames
combined_trend_results <- bind_rows(trend_results_race_HispLat, 
                                    trend_results_race_non_HispLat)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Hispanic/Latino",
                                                           "Non Hisp/Lat"))

# Sort the combined data frame
combined_trend_results <- combined_trend_results %>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)

# View the sorted combined dataframe
head(combined_trend_results)





################# EXPORT ###############

# Read the existing "XX Trend" sheet data
yrbs_master_analysis_stwd_trend <- read.xlsx("yrbs_master_analysis_statewide_trad.xlsx", sheet = "Race_HispLat Trend")

head(yrbs_master_analysis_stwd_trend)


# Convert Trend_Category to a factor with levels in the desired order
combined_trend_results$Trend_Category <- factor(combined_trend_results$Trend_Category, levels = c("Hispanic/Latino",
                                                           "Non Hisp/Lat"))


# Merge Long_Term_Trend into yrbs_master_stwd_grade based on matching ROI_Indicator_Code and Trend_Category
merged_data <- yrbs_master_analysis_stwd_trend %>%
  left_join(combined_trend_results %>% select(ROI_Indicator_Code, Trend_Category, Long_Term_Trend, Short_Term_Trend),
            by = c("ROI_Indicator_Code", "Trend_Category")) %>%
  select(School_Type,
         Health_Topic, 
         ROI_Indicator_Code, 
         Indicator_Long_Description, 
         Trend_Grouping,
         Trend_Category, 
         everything()) 
  

merged_data <- merged_data %>%
  mutate(Trend_Category = factor(Trend_Category,
                               levels = c("Hispanic/Latino",
                                          "Non Hisp/Lat")
                               ))%>%
  arrange(Health_Topic, ROI_Indicator_Code, Trend_Category)



head(merged_data)




# Load the workbook
wb <- loadWorkbook("yrbs_master_analysis_statewide_trad.xlsx")

# Overwrite the existing "XX Trend" sheet with the merged data
writeData(wb, sheet = "Race_HispLat Trend", merged_data)

# Save the workbook
saveWorkbook(wb, "yrbs_master_analysis_statewide_trad.xlsx", overwrite = TRUE)



```

\
